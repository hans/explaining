---
title             : "The title"
shorttitle        : "Title"

author: 
  - name          : "First Author"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "my@email.com"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
  - name          : "Ernst-August Doelle"
    affiliation   : "1,2"
    role:
      - Writing - Review & Editing

affiliation:
  - id            : "1"
    institution   : "Wilhelm-Wundt-University"
  - id            : "2"
    institution   : "Konstanz Business School"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  Abstract belongs here.
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["library.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r global_options, include=FALSE}
# knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
#                       fig.pos = "tb", fig.path='figs/',
#                       echo=F, warning=F, cache=F, 
#                       message=F, sanitize = T)

knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "")
getwd()
```

```{r libraries, echo=FALSE}
library(tidyverse)

# Regression and regression visualization tools
library(broom)
library(broom.mixed)
library(brms)
library(lme4)
library(lmerTest)

# Plotting
library(ggbeeswarm)
```
```{r custom functions, include=FALSE}
prepare_demo = function(demo_df) {
  age_responses = demo_df %>% 
    filter(internal_node_id == "0.0-0.0") %>% 
    mutate(survey_answer=as.integer(survey_answer))
  native_responses = demo_df %>% 
    filter(trial_type == "survey-multi-choice", survey_question_idx == 1)
  
  return(list(
    N=nrow(age_responses),
    
    age_mean=mean(age_responses$survey_answer),
    age_sd=sd(age_responses$survey_answer),
    age_min=min(age_responses$survey_answer),
    age_max=max(age_responses$survey_answer),
    
    date_min=min(age_responses$dateTime),
    date_max=max(age_responses$dateTime)
  ))
}

demo_chunk = function(demo_df) {
  p = papaja::printnum
  demo = prepare_demo(demo_df)
  cat(paste0("We recruited ", demo$N, " self-reported native English speakers ",
             "(age range: ", p(demo$age_min), "--", p(demo$age_max),
             ", mean: ", p(demo$age_mean), ", SD: ", p(demo$age_sd),
             ") from Amazon Mechanical Turk. "))
  cat("Workers were admitted only if the acceptance rate of their past HITs exceeded 95%. ")
  
  min_date_str = strftime(demo$date_min, "%B %Y")
  max_date_str = strftime(demo$date_max, "%B %Y")
  cat("The data were collected ")
  if (min_date_str == max_date_str) {
    cat(paste0("in ", min_date_str, "."))
  } else {
    cat(paste0("between ", min_date_str, " and ", max_date_str, "."))
  }
}

# Pipe shared across experiments: merge in relevant experimental materials and
# filter out items based on constraints shared across experiments.
merge_materials_and_filter = function(df) {
  df %>% 
    left_join(materials_df %>% select(materials_id, id, 
                                      `A concrete?`, `A countable?`, `A animate?`,
                                      `L plural?`, A, V, L),
              by=c("materials_id", "item_id"="id")) %>% 
    
    # Retain only concrete items.
    filter(`A concrete?` == TRUE)
  
  # TODO drop observations on items that were only present in earlier materials
  # revisions.
}

# Run a one-tailed t-test on filler responses within uniqueid, testing whether
# responses for some "high" condition exceed responses for some "low" condition.
# Adds at least two columns to the provided df:
#   - `exclude`: logical, TRUE iff uniqueid t-test passed
#   - `p.value`: float, p-value of t-test
run_slider_exclusions = function(slider_filler_df, condition_variable, 
                                 high_condition, low_condition, alpha=0.1) {
  ret = slider_filler_df %>% 
    group_by(uniqueid, {{condition_variable}}) %>% 
      nest() %>% 
        spread(key={{condition_variable}}, value=data) %>% 
        mutate(t_test=map2({{high_condition}}, {{low_condition}}, ~{
          tryCatch(
            {t.test(.x$slider_value, .y$slider_value, alternative="greater") %>% tidy()},
            error=function(e) {
              if (grepl("constant", as.character(e))) {
                # Responses are near-constant within-group. That could mean that
                # the subject is really consistent within-group and there is a
                # between-group difference, or they are simply responding the
                # same across trials. In the former case, we return a successful
                # p-value; in the latter, unsuccessful.
                if (mean(.x$slider_value) > mean(.y$slider_value)) {
                  tibble(p.value=0)
                } else {
                  tibble(p.value=1)
                }
              } else {
                # reraise
                stop(e)
              }
            }
          )
        })) %>% 
        select(-{{high_condition}}, -{{low_condition}}) %>% 
      unnest(t_test) %>% 
    mutate(exclude=p.value >= alpha)
  
  return(ret)
}

# Conduct a mixed-effects linear regression on Likert-scale acceptability
# responses in variable `slider_value`, contrasting an expected "good" and "bad"
# condition. Returns the model along with a dataframe describing "controlled"
# data points subtracting estimated random effects. This is useful for
# visualization.
#
# Returns a list containing
#   - `good_condition`: character
#   - `bad_condition`: character
#   - `model`: regression model
#   - `df_controlled`: `df` filtered to contain the relevant conditions, and
#     containing a new column `slider_value_controlled` which contains
#     `slider_value - ranef`, where `ranef` for a given row is the sum of
#     subject and item random effects estimated in the regression.
do_acceptability_regression = function(df, condition_col, good_condition, bad_condition) {
  df = df %>% filter({{condition_col}} %in% c(good_condition, bad_condition)) %>% 
    mutate(contrast = {{condition_col}} == good_condition)
  model = lmer(slider_value ~ contrast + (1|item_id) + (1|uniqueid),
               data=df,
               contrasts=list(contrast=c(`FALSE`=-1, `TRUE`=1)))
  
  # Compute item responses after controlling for random effects.
  slider_value_random = predict(model, random.only=T)
  df_controlled = cbind(df, slider_value_random) %>% 
    mutate(slider_value_controlled = slider_value - slider_value_random)
  
  return(list(good_condition=good_condition, bad_condition=bad_condition,
              model=model, df_controlled=df_controlled))
}
```

```{r load raw data, echo=FALSE}
DATA_VERSION = "2021-11-06-1831"
raw_df <- read_csv(paste0("../../data/raw_data.", DATA_VERSION, ".csv"),
                   na=c("", "nan"),
                   col_types=cols()) %>% 
  mutate(dateTime=lubridate::as_datetime(dateTime / 1000),
         item_id=as.factor(as.integer(item_id)))
```
```{r load materials, echo=FALSE}
all_items = raw_df %>% select(materials_id, item_id) %>% distinct()
load_json = function(materials_id) {
  jsonlite::read_json(paste0("../../materials/", materials_id, ".json"),
                         simplifyVector=T)$items %>% 
        add_column(materials_id=materials_id, .before=0) %>% 
        mutate(id=as.factor(as.integer(id))) %>% 
        relocate(id, .after=materials_id) %>% 
        type_convert()
}

materials_df <- na.omit(unique(all_items$materials_id)) %>% 
  map_dfr(possibly(load_json, otherwise=data.frame(), quiet=FALSE))
```


## Procedure

| $\rightarrow$ Given entity <br/> $\downarrow$ Construction | Agent/Theme | Location |
| - | - | - |
| A-construction | Bees! They are swarming in the garden. | The garden! Bees are swarming in it. |
| L-construction | Bees! The garden is swarming with them. | The garden! It is swarming with bees. | 

Table: An example experimental item varying across two factors: Given entity (Agent/Theme vs. Location) and Construction (A-construction vs. L-construction). TODO Bring in real prefix sentence, and maybe pick a better one. (ref:item-example)

(ref:stimuli) Participants were shown English passages consisting of two sentences. Each passage varied within-participant and within-item by two factors: *Given entity* and *Construction type*. An example item in four varying conditions is shown in \@ref(item-example).

The first sentence of each item established one of two possible event participants as a discourse referent: either the agent/theme (*Bees*) or the location (*The garden*), usually expressed using the exact same lexical item as in the following sentence, and in varying syntactic positions. (TODO introduce notion of establishing discourse referent.)

The second sentence then used either the A-construction or L-construction to express the relevant relation between Agent/Theme and Location. The participant established as given in the first sentence was expressed pronominally in the second sentence. Non-pronominal Agent/Theme participants were realized as bare NPs, while non-pronominal locations were realized with definite determiners (*the* or *his/her/their* depending on the context). The A-construction used locative prepositions matching the path and manner of motion coded by the verb. 

### Experimental structure

| Experiment | Behavior | Guiding question |
| - | - | - |
| [1](#experiment-swarm-comprehension-full) | Comprehension | Are comprehenders' meaning inferences sensitive to evident features of discourse structure? |
| C1 | Acceptability | Are A-constructions and L-constructions accepted by speakers? |
| C2 | Comprehension | Do comprehenders infer a meaning contrast between A-constructions and L-constructions? |
| [C3](#experiment-swarm-comprehension-control) | Comprehension | Do comprehenders infer a meaning contrast from our manipulations intended to influence discourse structure? |
| C4 | Production | Do speakers select between A-constructions and L-constructions based on discourse structure? |

Table: Overview of experiments.

## Experiments

### Acceptability experiment {#experiment-swarm-acceptability}

We first confirmed that our uses of the A-construction and L-construction were deemed acceptable by English speakers.

```{r load 02 data}
experiment_name = "02_acceptability_swarm"

df.02 = raw_df %>%
  filter(experiment_id == experiment_name,
         trial_type == "html-slider-response-with-copout") %>% 
  mutate(agent_is_subject = ifelse(condition_1 %in% c(0, 1), condition_1 == 1, NA)) %>% 
  
  merge_materials_and_filter

# Demographic information
df.02.demo = raw_df %>% 
  filter(experiment_id == experiment_name,
         trial_type %in% c("survey-text", "survey-multi-choice"))
```

#### Participants

```{r, results='asis'}
# TODO exclude native speakers
demo_chunk(df.02.demo)
```

#### Procedure

Subjects were presented with sentences drawn from our materials using either the A-construction or the L-construction, and asked to rate how "natural" each sentence was in each trial on a 7-point Likert scale. Each subject completed several practice trials prior to the experiment designed to calibrate this notion of a "natural" sentence.
We varied construction type both within-subject and within-item, and the assignment was pseudo-randomly counterbalanced across subjects.
Subjects were also presented with grammatical and ungrammatical filler sentences. Filler and experimental trials were pseudo-randomly shuffled

#### Exclusion criteria

```{r 02 exclusion}
subject.ttest.02 = run_slider_exclusions(
  df.02 %>% filter(condition_0 == "filler"), condition_1, good, bad)
Nretained.02 = nrow(subject.ttest.02 %>% filter(!exclude))

df.02.filtered = df.02 %>%
  left_join(subject.ttest.02 %>% select(uniqueid, exclude), by=c("uniqueid")) %>% 
  filter(exclude == FALSE)
```

We used subjects' performance on filler items to design an exclusion criterion. For each subject, we collect their Likert responses on filler items, which have ground-truth "acceptable" and "unacceptable" labels. We then perform a two-sample one-tailed $t$-test between these groups. We retain only those subjects for which we find that $\text{rating}_\text{acceptable} > \text{rating}_\text{unacceptable}$ with one-tailed $p < 0.1$.

`r Nretained.02` subjects (`r Nretained.02 / nrow(subject.ttest.02) * 100`%) were retained by this criterion.

#### Results

```{r 02 slider visualization}
df.02 %>%
  
  # Join in filler t-test results
  full_join(select(subject.ttest.02, uniqueid, exclude, p.value) %>% rename(filler.p.value=p.value),
            by=c("uniqueid")) %>% 
  
  mutate(
    # Reorder subjects based on filler test p-value
    uniqueid=fct_reorder(uniqueid, filler.p.value)) %>%
  
  ggplot(aes(x=uniqueid, y=slider_value, color=condition_1)) +
    
    geom_quasirandom(groupOnX=TRUE, alpha=0.4, data=. %>% filter(condition_1 %in% c(0, 1))) +
    scale_color_discrete(name="Stimulus condition",
                         labels=c(`0`="L-construction", `1`="A-construction",
                                  "bad"="Ungrammatical filler", "good"="Grammatical filler")) +
  
    # Plot boxplots for fillers
    geom_boxplot(alpha=0.2, data=. %>% filter(condition_1 == "good")) +
    geom_boxplot(alpha=0.2, data=. %>% filter(condition_1 == "bad")) +
  
    # Shade based on exclusion
    geom_rect(data=. %>% group_by(uniqueid) %>% filter(row_number() == 1),
              aes(xmin = as.numeric(uniqueid) - 0.5, xmax = as.numeric(uniqueid) + 0.5,
                  ymin = 1, ymax = 7, fill = exclude),
              alpha = 0.1, color=NA) +
    scale_fill_discrete(name="Excluded?", labels=c(`FALSE`="No", `TRUE`="Yes")) +
  
    scale_x_discrete(name="Subject", labels=1:nrow(subject.ttest.02)) +
    scale_y_continuous(name="Acceptability rating", breaks=c(1, 2, 3, 4, 5, 6, 7))
```

```{r 02 regression}
lmer.02.A = do_acceptability_regression(df.02.filtered, condition_1, 1, "bad")
lmer.02.L = do_acceptability_regression(df.02.filtered, condition_1, 0, "bad")

lmer.02.A.tidy = lmer.02.A$model %>% tidy
lmer.02.L.tidy = lmer.02.L$model %>% tidy
```

```{r, fig.cap="Acceptability responses for L-construction, A-construction, and ungrammatical filler items."}
# TODO this is a very unintuitive graph, because it reveals how our regression assumptions are violated :)
# After controlling for estimated subject/item effets, some responses are higher than 7!
rbind(lmer.02.A$df_controlled, lmer.02.L$df_controlled) %>% 
  ggplot(aes(x=condition_1, y=slider_value_controlled)) +
  geom_boxplot() +
  geom_quasirandom(alpha=0.3) +
  scale_y_continuous(name="Acceptability rating", breaks=c(1, 2, 3, 4, 5, 6, 7)) +
  scale_x_discrete(name="Condition", labels=c(`0`="L-construction", `1`="A-construction", "bad"="Ungrammatical fillers"))
```


#### Conclusion

TODO

### Two-sentence acceptability experiment {#experiment-swarm-acceptability-two}

Our full experiments use stimuli containing two sentences each. The first sentence establishes an entity as topical, and the second sentence uses the A-construction or L-construction with that entity expressed anaphorically. We next tested whether these two-sentence stimuli were natural for English speakers.

```{r load 02 data}
experiment_name = "08_acceptability_swarm-withprefix"

df.08 = raw_df %>%
  filter(experiment_id == experiment_name,
         trial_type == "html-slider-response-with-copout") %>% 
  mutate(agent_is_subject = ifelse(condition_1 %in% c(0, 1), condition_1 == 1, NA),
         agent_is_given = ifelse(condition_0 %in% c(0, 1), condition_0 == 0, NA),
         condition = ifelse(condition_0 == "filler", paste(condition_0, condition_1),
                            paste0("c", ifelse(agent_is_subject, "A", "L"),
                                   "g", ifelse(agent_is_given, "A", "L")))) %>% 
  
  merge_materials_and_filter

# Demographic information
df.08.demo = raw_df %>% 
  filter(experiment_id == experiment_name,
         trial_type %in% c("survey-text", "survey-multi-choice"))
```

#### Participants

```{r, results='asis'}
# TODO exclude native speakers
demo_chunk(df.08.demo)
```

#### Procedure

Subjects were presented with sentences drawn from our materials using either the A-construction or the L-construction, and asked to rate how "natural" each sentence was in each trial on a 7-point Likert scale. Each subject completed several practice trials prior to the experiment designed to calibrate this notion of a "natural" sentence.
We varied construction type both within-subject and within-item, and the assignment was pseudo-randomly counterbalanced across subjects.
Subjects were also presented with grammatical and ungrammatical filler sentences. Filler and experimental trials were pseudo-randomly shuffled

#### Exclusion criteria

```{r 08 exclusion}
subject.ttest.08 = run_slider_exclusions(
  df.08 %>% filter(condition_0 == "filler"), condition_1, good, bad)
Nretained.08 = nrow(subject.ttest.08 %>% filter(!exclude))

df.08.filtered = df.08 %>%
  left_join(subject.ttest.08 %>% select(uniqueid, exclude), by=c("uniqueid")) %>% 
  filter(exclude == FALSE)
```

We used subjects' performance on filler items to design an exclusion criterion. For each subject, we collect their Likert responses on filler items, which have ground-truth "acceptable" and "unacceptable" labels. We then perform a two-sample one-tailed $t$-test between these groups. We retain only those subjects for which we find that $\text{rating}_\text{acceptable} > \text{rating}_\text{unacceptable}$ with one-tailed $p < 0.1$.

`r Nretained.08` subjects (`r Nretained.08 / nrow(subject.ttest.08) * 100`%) were retained by this criterion.

#### Results

```{r 08 slider visualization}
df.08 %>%

  # Join in filler t-test results
  full_join(select(subject.ttest.08, uniqueid, exclude, p.value) %>% rename(filler.p.value=p.value),
            by=c("uniqueid")) %>% 
  
  mutate(
    # Reorder subjects based on filler test p-value
    uniqueid=fct_reorder(uniqueid, filler.p.value),
    
    plot_group=ifelse(condition_0 == "filler", condition_1,
                      "exp")) %>%
  
  ggplot(aes(x=uniqueid, y=slider_value, color=plot_group)) +
    
    geom_quasirandom(groupOnX=TRUE, alpha=0.4, data=. %>% filter(plot_group == "exp")) +
    scale_color_discrete(name="Stimulus type",
                         labels=c("exp"="Experimental item",
                                  "bad"="Ungrammatical filler", "good"="Grammatical filler")) +
  
    # Plot boxplots for fillers
    geom_boxplot(alpha=0.2, data=. %>% filter(condition_1 == "good")) +
    geom_boxplot(alpha=0.2, data=. %>% filter(condition_1 == "bad")) +
  
    # Shade based on exclusion
    geom_rect(data=. %>% group_by(uniqueid) %>% filter(row_number() == 1),
              aes(xmin = as.numeric(uniqueid) - 0.5, xmax = as.numeric(uniqueid) + 0.5,
                  ymin = 1, ymax = 7, fill = exclude),
              alpha = 0.1, color=NA) +
    scale_fill_discrete(name="Excluded?", labels=c(`FALSE`="No", `TRUE`="Yes")) +
  
    scale_x_discrete(name="Subject", labels=1:nrow(subject.ttest.08)) +
    scale_y_continuous(name="Acceptability rating", breaks=c(1, 2, 3, 4, 5, 6, 7))
```

```{r 08 regression}
# TODO how to do this properly in a single regression?

conditions.08 = c("cAgA", "cAgL", "cLgL", "cLgA")
lmer.08 = conditions.08 %>% 
  map(~do_acceptability_regression(df.08.filtered, condition, .x, "filler bad"))

# join tidy results
lmer.08 %>% map_dfr(~.x$model %>% tidy() %>% add_column(condition=.x$good_condition, .before=0))
```

```{r 08 boxplots, fig.cap="Acceptability responses for two-sentence stimuli and ungrammatical filler items."}
# TODO this is a very unintuitive graph, because it reveals how our regression assumptions are violated :)
# After controlling for estimated subject/item effects, some responses are higher than 7!
lmer.08 %>% map_dfr(~.x$df_controlled) %>% 
  ggplot(aes(x=condition, y=slider_value_controlled)) +
  geom_boxplot() +
  geom_quasirandom(alpha=0.3) +
  scale_y_continuous(name="Acceptability rating", breaks=c(1, 2, 3, 4, 5, 6, 7))

  # TODO make this scale
  # scale_x_discrete(name="Condition", labels=c(`0`="L-construction", `1`="A-construction", "bad"="Ungrammatical fillers"))
```

### Basic comprehension experiment {#experiment-swarm-comprehension-basic}

To the best of our knowledge, no empirical test of the meaning contrast between the A- and L-construction exists. We first ran an experiment to test whether English speakers recognized this meaning contrast.

```{r}
experiment_name = "00_comprehension_swarm-construction-meaning"

df.00 = raw_df %>%
  filter(experiment_id == experiment_name,
         trial_type == "html-slider-response-with-copout") %>% 
  mutate(agent_is_subject = ifelse(condition_1 %in% c(0, 1), condition_1 == 1, NA)) %>%
  
  merge_materials_and_filter

# Drop subjects from early pilot trials which did not include the full set of
# fillers.
df.00.drops = df.00 %>% 
  filter(condition_0 == "filler") %>% 
  group_by(uniqueid) %>% 
    summarise(n=n()) %>% 
  filter(n < 12)
df.00 = df.00 %>% anti_join(df.00.drops, by=c("uniqueid"))

# Demographic information
df.00.demo = raw_df %>% 
  # Perform same exclusion as above
  anti_join(df.00.drops, by=c("uniqueid")) %>% 
  filter(experiment_id == experiment_name,
         trial_type %in% c("survey-text", "survey-multi-choice"))
```

#### Participants

```{r, results='asis'}
# TODO exclude native speakers
demo_chunk(df.00.demo)
```

#### Procedure

Subjects were presented with sentences drawn from our materials using either the A-construction or L-construction. This construction type was varied both within-subject and within-item, and the assignment was pseudo-randomly counterbalanced across subjects.

TODO describe fillers.

In each trial, subjects were asked: "How much/many \<Agent/Theme> is/are in/on \<Location>?" They responded using a slider interface whose value ranged from 0 to 100. The ends of the slider were labeled to suggest a scale relative to the size of the Location, where a value of 100 indicates that the Location is as full as it could be of the Agent/Theme, and a value of 0 indicates that the Location contains none of the Agent/Theme.

TODO include vignette.

TODO copout.

#### Exclusion criteria {#swarm-slider-exclusion-criteria}

The filler items of the experiment all denoted scenes with clearly empty or full locations. We used subjects' responses on these filler items to check their attention and design an exclusion criterion. For each subject, we collect their responses on filler items with ground-truth "full" locations and ground-truth "empty" locations. We then perform a two-sample one-tailed $t$-test between the two groups. We retain only those subjects for whom this test yields $\text{fullness}_\text{full} > \text{fullness}_\text{empty}$ with a one-tailed $p < 0.1$.

```{r 00 exclusion}
subject.ttest.00 = run_slider_exclusions(
  df.00 %>% filter(condition_0 == "filler"), condition_1, full, empty)
Nretained.00 = nrow(subject.ttest.00 %>% filter(!exclude))

df.00.filtered = df.00 %>% 
  left_join(subject.ttest.00 %>% select(uniqueid, exclude), by=c("uniqueid")) %>% 
  filter(exclude == FALSE)
```

`r Nretained.00` subjects (`r Nretained.00 / nrow(subject.ttest.00) * 100`%) were retained by this criterion.

#### Results

```{r 00 slider visualization}
df.00 %>%
  
  # Join in filler t-test results
  full_join(select(subject.ttest.00, uniqueid, exclude, p.value) %>% rename(filler.p.value=p.value),
            by=c("uniqueid")) %>% 
  
  mutate(
    # Reorder subjects based on p-value of filler t-test
    uniqueid=fct_reorder(uniqueid, filler.p.value),
    
    plot_group=ifelse(condition_0 == "filler", condition_1,
                      "exp")) %>%
  
  ggplot(aes(x=uniqueid, y=slider_value, color=plot_group)) +
    
    geom_quasirandom(groupOnX=TRUE, alpha=0.4, data=. %>% filter(plot_group == "exp")) +
    scale_color_discrete(name="Stimulus type",
                         labels=c("exp"="Experimental item",
                                  "empty"="Empty filler", "full"="Full filler")) +
  
    # Plot boxplots for fillers
    geom_boxplot(alpha=0.2, data=. %>% filter(condition_1 == "full")) +
    geom_boxplot(alpha=0.2, data=. %>% filter(condition_1 == "empty")) +
  
    # Shade based on exclusion
    geom_rect(data=. %>% group_by(uniqueid) %>% filter(row_number() == 1),
              aes(xmin = as.numeric(uniqueid) - 0.5, xmax = as.numeric(uniqueid) + 0.5,
                  ymin = 0, ymax = 100, fill = exclude),
              alpha = 0.1, color=NA) +
    scale_fill_discrete(name="Excluded?", labels=c(`FALSE`="No", `TRUE`="Yes")) +
  
    scale_x_discrete(name="Subject", labels=1:nrow(subject.ttest.00)) +
    scale_y_continuous(name="Fullness rating") +
    theme()
```


```{r}
# TODO render controlled response figure
```

We evaluated the effect of our experimental manipulation using a Bayesian mixed-effects beta regression. We entered the manipulations *Given entity* (sum-coded; Location = -1, Agent/Theme = 1) and *Construction type* (sum-coded; A-construction = -1, L-construction = 1) as fixed effects in the regression, along with the interaction of the two variables. (Note that both manipulations are coded such that we should expect a higher rating on the fullness measure for positive values of the factor.)
We used a maximal random effect structure, including all logically possible by-subject and by-item random slopes and intercepts.

```{r}
# TODO Bayesian regression
```

TODO report results

#### Conclusion

### Production experiment {#experiment-swarm-production-givenness}

We next confirmed that speakers were willing to select between the A-construction and L-construction based on given entities in the discourse.
TODO ref theoretical reason to expect this.
This has not been empirically confirmed for these particular constructions. TODO what are the reasons to think *a priori* that realizing as subject might be under different pressures than alternation of postverbal content as in the dative alternation?

#### Participants

#### Procedure

This experiment used the complete two-sentence stimuli described in \@ref(stimuli). Subjects performed forced-choice judgments over pairs of these stimuli which differed only in their second sentence. Thus each trial held a *Given entity* fixed while contrasting the two construction types. The factor of *Given entity* was manipulated within-subject and within-item, and assignment was pseudo-randomly counterbalanced among subjects.

We asked subjects to judge which was the more "natural" of the two stimuli. The experiment contained TODO filler items which contrasted grammatical and ungrammatical (or highly unnatural) English text.

#### Exclusion criteria {#swarm-2afc-exclusion-criteria}

TODO what did we do here?

```{r}
# TODO do exclusion here
```

#### Results

```{r}
# TODO render controlled response figure
```

```{r cache=TRUE}
# TODO Bayesian regression
```


#### Conclusion

### Control comprehension experiment {#experiment-swarm-comprehension-control}

### Critical explaining-away experiment {#experiment-swarm-comprehension-full}

\@ref(experiment-swarm-comprehension-basic) confirmed that English speakers infer a meaning contrast between the A-construction and L-construction. \@ref(experiment-swarm-production) further confirmed that English speakers know to select between the A-construction and L-construction in response to features of the discourse. In this final experiment, we test whether English speakers use this knowledge about the multiple pressures faced by the speaker in selecting a construction to resolve potential meaning ambiguities.

#### Participants

#### Procedure

We presented subjects with the two-sentence stimuli described in \@ref(stimuli). We manipulated the two relevant factors (*Given entity*, determined by the first sentence, establishing either the Agent/Theme or Location as a referent; and *Construction type*, evident in the second sentence, using either the A-construction or L-construction). Both manipulations were within-subject and within-item, pseudo-randomly counterbalanced between subjects.

We used the same slider interface as described in \@ref(experiment-swarm-comprehension-basic). An example trial is shown in TODO.

TODO filler items

TODO copout

#### Exclusion criteria

We used the same exclusion criteria as in \@ref(experiment-swarm-comprehension-basic).

```{r}
# TODO do exclusion here
```

#### Results


The text of the paper should be formatted in two columns with an
overall width of 7 inches (17.8 cm) and length of 9.25 inches (23.5
cm), with 0.25 inches between the columns. Leave two line spaces
between the last author listed and the text of the paper; the text of
the paper (starting with the abstract) should begin no less than 2.75 inches below the top of the
page. The left margin should be 0.75 inches and the top margin should
be 1 inch.  \textbf{The right and bottom margins will depend on
whether you use U.S. letter or A4 paper, so you must be sure to
measure the width of the printed text.} Use 10~point Times Roman
with 12~point vertical spacing, unless otherwise specified.

The title should be in 14~point bold font, centered. The title should
be formatted with initial caps (the first letter of content words
capitalized and the rest lower case). In the initial submission, the
phrase ``Anonymous CogSci submission'' should appear below the title,
centered, in 11~point bold font.  In the final submission, each
author's name should appear on a separate line, 11~point bold, and
centered, with the author's email address in parentheses. Under each
author's name list the author's affiliation and postal address in
ordinary 10~point type.

Indent the first line of each paragraph by 1/8~inch (except for the
first paragraph of a new section). Do not add extra vertical space
between paragraphs.


# First-Level Headings

First level headings should be in 12 point , initial caps, bold and
centered. Leave one line space above the heading and 1/4~line space
below the heading.

## Second-Level Headings

Second level headings should be 11 point , initial caps, bold, and
flush left. Leave one line space above the heading and 1/4~ line
space below the heading.

### Third-Level Headings

Third-level headings should be 10 point , initial caps, bold, and flush
left. Leave one line space above the heading, but no space after the
heading.

# Formalities, Footnotes, and Floats

Use standard APA citation format. Citations within the text should
include the author's last name and year. If the authors' names are
included in the sentence, place only the year in parentheses, as in
[-@NewellSimon1972a], but otherwise place the entire reference in
parentheses with the authors and year separated by a comma
[@NewellSimon1972a]. List multiple references alphabetically and
separate them by semicolons [@ChalnickBillman1988a; @NewellSimon1972a]. 
Use the et. al. construction only after listing all the authors to a
publication in an earlier reference and for citations with four or
more authors.

For more information on citations in RMarkdown, see **[here](http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html#citations).**

## Footnotes

Indicate footnotes with a number\footnote{Sample of the first
footnote.} in the text. Place the footnotes in 9 point type at the
bottom of the page on which they appear. Precede the footnote with a
horizontal rule.\footnote{Sample of the second footnote.} You can also use 
markdown formatting to include footnotes using this syntax [^1].

[^1]: Sample of a markdown footnote.

## Figures

All artwork must be very dark for purposes of reproduction and should
not be hand drawn. Number figures sequentially, placing the figure
number and caption, in 10 point, after the figure with one line space
above the caption and one line space below it. If necessary, leave extra white space at
the bottom of the page to avoid splitting the figure and figure
caption. You may float figures to the top or bottom of a column, or
set wide figures across both columns.

## Two-column images

You can read local images using png package for example and plot 
it like a regular plot using grid.raster from the grid package. 
With this method you have full control of the size of your image. **Note: Image must be in .png file format for the readPNG function to work.**

You might want to display a wide figure across both columns. To do this, you change the `fig.env` chunk option to `figure*`. To align the image in the center of the page, set `fig.align` option to `center`. To format the width of your caption text, you set the `num.cols.cap` option to `2`.

```{r 2-col-image, fig.env = "figure*", fig.pos = "h", fig.width=4, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "This image spans both columns. And the caption text is limited to 0.8 of the width of the document."}
img <- png::readPNG("figs/walrus.png")
grid::grid.raster(img)
```

## One-column images

Single column is the default option, but if you want set it explicitly, set `fig.env` to `figure`. Notice that the `num.cols` option for the caption width is set to `1`.

```{r image, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=2, fig.height=2, set.cap.width=T, num.cols.cap=1, fig.cap = "One column image."}
# img <- png::readPNG("figs/lab_logo_stanford.png")
# grid::grid.raster(img)
```


## R Plots

You can use R chunks directly to plot graphs. And you can use latex floats in the
fig.pos chunk option to have more control over the location of your plot on the page. For more information on latex placement specifiers see **[here](https://en.wikibooks.org/wiki/LaTeX/Floats,_Figures_and_Captions)**

```{r plot, fig.env="figure", fig.pos = "H", fig.align = "center", fig.width=2, fig.height=2, fig.cap = "R plot" }
# x <- 0:100
# y <- 2 * (x + rnorm(length(x), sd = 3) + 3)
# 
# ggplot2::ggplot(data = data.frame(x, y), 
#                 aes(x = x, y = y)) + 
#   geom_point() + 
#   geom_smooth(method = "lm")
```


# Acknowledgements

Place acknowledgments (including funding information) in a section at
the end of the paper.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
